{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Regression with CAPM\n",
    "This code is for making a simple CAPM Regression Model using Dr. French's Historical Data and the TD Ameritrade API's Candle Data\n",
    "\n",
    "It takes data from: \n",
    "- TD Ameritrade and tda-api: https://developer.tdameritrade.com/ & https://tda-api.readthedocs.io/en/latest/\n",
    "- Dr. Kenneth R. French's Data Library(for risk-free rates and market rates): https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html\n",
    "\n",
    "This notebook also utilizes some prewritten functions to pull data without the big setups required for the tda-api, and can be found in the configs.py file in the functions subfolder\n",
    "\n",
    "The Configs and CSV Data Files will be saved in the repository /Users/dB/.secret/ under the filename 'tda-api-v6.json' and pathname 'ff-research-data'. Their paths are listed here for easier access while I write in this notebook:\n",
    "\n",
    "/Users/dB/.secret/tda-api-v6.json\n",
    "\n",
    "/Users/dB/.secret/ff-research-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Packages and Add Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports -----------------------------------------------------------------------------\n",
    "import functions_for_notebooks.configs as c\n",
    "from tda.client import Client\n",
    "from tda import auth as a\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Configs -----------------------------------------------------------------------------\n",
    "tda_api_json_path = '/Users/dB/.secret/tda-api-v6.json'\n",
    "tda_api_json = c.get_account_data(tda_api_json_path)\n",
    "\n",
    "ff_data_path = '/Users/dB/.secret/ff-research-data/F-F_Research_Data_Factors.CSV'\n",
    "ff_data_weekly_path = '/Users/dB/.secret/ff-research-data/F-F_Research_Data_Factors_weekly.CSV'\n",
    "ff_data_daily_path = '/Users/dB/.secret/ff-research-data/F-F_Research_Data_Factors_daily.csv'\n",
    "\n",
    "start_datetime = '01/01/2019' # Collect Data from the Last 5 Years\n",
    "\n",
    "symbol = 'AMD'\n",
    "periods = '1d'\n",
    "periods2 = '1w'\n",
    "end = dt.datetime.now() # Today's Date\n",
    "start = end - dt.timedelta(days = 1825) # Subtract 5 Years from Today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect Data and Process into DataFrames\n",
    "\n",
    "To collect the data, we need to read Dr. French's CSVs for data and call the TD Ameritrade API for candle data.\n",
    "\n",
    "Reading Dr. French's CSVs is a simple process, all we need to do is decide to use daily or weekly data and then call Panda's read_from_csv() function. We will need to translate the dates into datetime objects to match up with the API data [ADD LATER]\n",
    "\n",
    "Calling the API will pull down candle data for a stock. This will provide us with the open, close, high, low and volume data for the specified timeframe. Since Dr. French's Data only has daily and weekly entries for the data, we should only call tda-api's Client.get_price_history_every_day() or Client.get_price_history_every_week() functions so the dates match. \n",
    "\n",
    "I have a function from the dBI project named get_price_history_df() that can call the API once a Client object is created, and we can pass in '1d' and '1w' as the periods parameter for the daily and weekly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'functions_for_notebooks.configs' has no attribute 'read_ff_csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctions_for_notebooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mc\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Get the Data from the CSV\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m daily_data \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_ff_csvs\u001b[49m(ff_data_daily_path)\n\u001b[1;32m      4\u001b[0m weekly_data \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mread_ff_csvs(ff_data_weekly_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'functions_for_notebooks.configs' has no attribute 'read_ff_csvs'"
     ]
    }
   ],
   "source": [
    "import functions_for_notebooks.configs as c\n",
    "# Get the Data from the CSV\n",
    "daily_data = c.read_ff_csvs(ff_data_daily_path)\n",
    "weekly_data = c.read_ff_csvs(ff_data_weekly_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our API Parameters for the Candle Data Call\n",
    "ak = tda_api_json['api_key']\n",
    "ru = tda_api_json['redirect_uri']\n",
    "tp = tda_api_json['token_path']\n",
    "\n",
    "# Create the tda.Client object to call the API\n",
    "client = c.connect_to_api(ak, ru, tp)\n",
    "\n",
    "# Call the API for candle data\n",
    "candles_daily = c.get_price_history_df(client, symbol, '1d', start, end)\n",
    "candles_weekly = c.get_price_history_df(client, symbol, '1w', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dBI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
